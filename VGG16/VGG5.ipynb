{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "19dd142d-af4f-4cc4-a737-cb5cf859e92e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-08T07:41:18.244272Z",
          "iopub.status.busy": "2025-05-08T07:41:18.242351Z",
          "iopub.status.idle": "2025-05-08T07:41:18.340635Z",
          "shell.execute_reply": "2025-05-08T07:41:18.338962Z",
          "shell.execute_reply.started": "2025-05-08T07:41:18.244202Z"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0c1f6b554ac6424d8233317b55897939",
            "33e27e3331b44c8abde8e85db5b7207d",
            "a2dd34b016d548eb9aee47840d68ee75"
          ]
        },
        "id": "19dd142d-af4f-4cc4-a737-cb5cf859e92e",
        "outputId": "5903c7b7-45fc-4895-f5fa-cde537fe1300"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileUpload(value={}, description='Upload')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c1f6b554ac6424d8233317b55897939"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display\n",
        "import os\n",
        "\n",
        "# 上傳檔案（會跳出檔案選擇器）\n",
        "from ipywidgets import FileUpload\n",
        "\n",
        "upload = FileUpload()\n",
        "display(upload)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "172906a3-1dd5-4484-a903-2877d1e50ebc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-08T07:41:25.642301Z",
          "iopub.status.busy": "2025-05-08T07:41:25.641367Z",
          "iopub.status.idle": "2025-05-08T07:41:25.678931Z",
          "shell.execute_reply": "2025-05-08T07:41:25.676984Z",
          "shell.execute_reply.started": "2025-05-08T07:41:25.642244Z"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "172906a3-1dd5-4484-a903-2877d1e50ebc",
        "outputId": "7418cca3-2a6c-4595-9835-3460e0bac6df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'metadata': {'name': 'kaggle.json', 'type': 'application/json', 'size': 64, 'lastModified': 1745215961986}, 'content': b'{\"username\":\"suchiwen\",\"key\":\"01a925cee9e9e9d232008524b0434fb9\"}'}\n",
            "kaggle.json 已成功儲存至 /root/.kaggle/kaggle.json\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# 假設你只上傳了一個檔案\n",
        "# Check if any file is uploaded and get the filename\n",
        "if upload.value:\n",
        "    # Get the first (and likely only) filename from the dictionary keys\n",
        "    filename = list(upload.value.keys())[0]\n",
        "    fileinfo = upload.value[filename] # Access the file info dictionary using the filename as key\n",
        "else:\n",
        "    print(\"No file uploaded.\")\n",
        "    # Handle the case where no file is uploaded, perhaps by exiting or prompting the user.\n",
        "    # For this example, we'll assume a file was uploaded as per the traceback context.\n",
        "    raise FileNotFoundError(\"No file was uploaded.\")\n",
        "\n",
        "\n",
        "# 顯示內容結構（除錯用）\n",
        "print(fileinfo)\n",
        "\n",
        "# 儲存 kaggle.json\n",
        "# filename is already obtained above\n",
        "content = fileinfo['content']\n",
        "\n",
        "kaggle_dir = Path.home() / \".kaggle\"\n",
        "kaggle_dir.mkdir(exist_ok=True)\n",
        "\n",
        "kaggle_json_path = kaggle_dir / \"kaggle.json\"\n",
        "with open(kaggle_json_path, \"wb\") as f:\n",
        "    f.write(content)\n",
        "\n",
        "# 設定權限（Linux/macOS 建議）\n",
        "os.chmod(kaggle_json_path, 0o600)\n",
        "\n",
        "print(f\"{filename} 已成功儲存至 {kaggle_json_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "e13e384c-f12d-4c02-b891-80542dd9a6db",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-08T07:41:27.613483Z",
          "iopub.status.busy": "2025-05-08T07:41:27.612703Z",
          "iopub.status.idle": "2025-05-08T07:41:28.600387Z",
          "shell.execute_reply": "2025-05-08T07:41:28.597973Z",
          "shell.execute_reply.started": "2025-05-08T07:41:27.613424Z"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e13e384c-f12d-4c02-b891-80542dd9a6db",
        "outputId": "065ad854-b822-438f-e9e3-260583f219ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                     title                                                  size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
            "------------------------------------------------------  ----------------------------------------------  -----------  --------------------------  -------------  ---------  ---------------  \n",
            "fedesoriano/cifar100                                    CIFAR-100 Python                                  168517809  2020-12-26 08:37:10.143000          12526        178  1.0              \n",
            "pankrzysiu/cifar10-python                               CIFAR-10 Python                                   340613496  2018-01-27 13:42:40.967000          15066        255  0.75             \n",
            "petitbonney/cifar10-image-recognition                   CIFAR-10                                         1007971063  2019-10-01 12:50:23.227000           2977         27  0.8235294        \n",
            "valentynsichkar/cifar10-preprocessed                    CIFAR10 Preprocessed                             1227571899  2019-07-13 13:43:11.030000           3417         65  1.0              \n",
            "swaroopkml/cifar10-pngs-in-folders                      CIFAR-10 PNGs in folders                          293479104  2019-02-10 11:16:19.507000          13674         96  0.6875           \n",
            "ayush1220/cifar10                                       CIFAR-10                                          146259525  2022-01-11 21:03:48.427000           1433         13  0.6875           \n",
            "fedesoriano/cifar10-python-in-csv                       CIFAR-10 Python in CSV                            218807675  2021-06-22 09:07:55.670000           7195         53  1.0              \n",
            "alincijov/cifar-100                                     CIFAR-100                                         168517809  2020-09-13 13:40:25.763000            382         16  0.625            \n",
            "quanbk/cifar10                                          Cifar-10                                          170062484  2017-11-22 01:12:26.240000           3663         26  0.25             \n",
            "emadtolba/cifar10-comp                                  Cifar-10 comp                                     706709151  2018-09-09 02:55:22.263000            384         12  0.64705884       \n",
            "birdy654/cifake-real-and-ai-generated-synthetic-images  CIFAKE: Real and AI-Generated Synthetic Images    109625224  2023-03-28 16:00:29.500000          20625        152  0.875            \n",
            "amishfaldu/cifar10dataset                               Cifar-10 Dataset                                 4989376312  2020-10-07 04:30:40.600000            356          6  1.0              \n",
            "ibraheemmoosa/cifar100-256x256                          CIFAR100 256x256                                 2817065558  2021-04-24 17:09:57.140000           1040         23  0.875            \n",
            "jessicali9530/stl10                                     STL-10 Image Recognition Dataset                 2017846807  2018-06-11 03:02:24.153000           6901        125  0.75             \n",
            "gazu468/cifar10-classification-image                    Cifar10 Classification Image                      146259525  2022-10-29 18:47:18.453000            822         15  0.5              \n",
            "oxcdcd/cifar10                                          cifar10                                           183819211  2018-08-12 09:31:35.253000           3462         35  0.1875           \n",
            "pavansanagapati/cifar100                                CIFAR-100                                         337036008  2018-06-21 12:23:51.707000            417          4  0.3125           \n",
            "ekaakurniawan/the-cifar10-dataset                       The CIFAR-10 Dataset                              170063312  2021-04-06 16:57:56.220000            523          4  0.9375           \n",
            "pypiahmad/cifar-100                                     CIFAR-100                                         168517947  2023-10-29 09:53:59.520000             84         11  0.6875           \n",
            "imsparsh/musicnet-dataset                               MusicNet Dataset                                23086004822  2021-02-18 14:12:19.753000          16207        528  1.0              \n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets list -s cifar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "2e5fb396-b2e8-4b41-a76c-81dcd0626c01",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-08T07:41:57.870318Z",
          "iopub.status.busy": "2025-05-08T07:41:57.868472Z",
          "iopub.status.idle": "2025-05-08T07:51:56.665414Z",
          "shell.execute_reply": "2025-05-08T07:51:56.664055Z",
          "shell.execute_reply.started": "2025-05-08T07:41:57.870233Z"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e5fb396-b2e8-4b41-a76c-81dcd0626c01",
        "outputId": "6bcedc94-b822-41a5-d7f7-383a95e0740e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.3.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "Downloading dog-breed-identification.zip to /content\n",
            " 96% 662M/691M [00:05<00:00, 42.2MB/s]\n",
            "100% 691M/691M [00:05<00:00, 132MB/s] \n"
          ]
        }
      ],
      "source": [
        "!pip install -U kaggle\n",
        "!pip install --upgrade pandas\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# 建立 Kaggle 資料夾\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# 下載 Dog Breed Identification 資料集\n",
        "!kaggle competitions download -c dog-breed-identification --force\n",
        "!unzip -oq dog-breed-identification.zip -d dog-breed-identification\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "labels = pd.read_csv('dog-breed-identification/labels.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, random_split\n",
        "from torchvision import transforms\n",
        "\n",
        "# ---------- 參數設定 ----------\n",
        "data_dir = \"dog-breed-identification\"\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "labels_path = os.path.join(data_dir, \"labels.csv\")\n",
        "val_ratio = 0.2\n",
        "batch_size = 32\n",
        "num_workers = 2\n",
        "gamma = 2.0  # Focal Loss gamma\n",
        "num_epochs = 10\n",
        "lr = 1e-4\n",
        "\n",
        "# ---------- 資料增強 ----------\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "def cutmix(data, targets, alpha=1.0):\n",
        "    indices = torch.randperm(data.size(0))\n",
        "    shuffled_data = data[indices]\n",
        "    shuffled_targets = targets[indices]\n",
        "\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    bbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\n",
        "    data[:, :, bbx1:bbx2, bby1:bby2] = shuffled_data[:, :, bbx1:bbx2, bby1:bby2]\n",
        "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (data.size(-1) * data.size(-2)))\n",
        "    return data, targets, shuffled_targets, lam\n",
        "\n",
        "def rand_bbox(size, lam):\n",
        "    W = size[2]\n",
        "    H = size[3]\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = int(W * cut_rat)\n",
        "    cut_h = int(H * cut_rat)\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "    return bbx1, bby1, bbx2, bby2\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(0.1, 0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "    RandomErasing(p=0.5),\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "WgWfz5uF5BT1"
      },
      "id": "WgWfz5uF5BT1",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 自訂 Dataset ----------\n",
        "class DogBreedDataset(Dataset):\n",
        "    def __init__(self, image_dir, labels_df, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.labels_df = labels_df\n",
        "        self.breed2idx = {breed: idx for idx, breed in enumerate(sorted(labels_df['breed'].unique()))}\n",
        "        self.labels_df['label'] = self.labels_df['breed'].map(self.breed2idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.labels_df.iloc[idx]\n",
        "        img_path = os.path.join(self.image_dir, row['id'] + \".jpg\")\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        label = row['label']\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# ---------- 讀入標籤 ----------\n",
        "labels = pd.read_csv(labels_path)\n",
        "\n",
        "# ---------- 建立 Dataset 與切分 ----------\n",
        "full_dataset = DogBreedDataset(train_dir, labels, transform=train_transform)\n",
        "val_size = int(len(full_dataset) * val_ratio)\n",
        "train_size = len(full_dataset) - val_size\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# 替驗證集設定不同 transform\n",
        "val_dataset.dataset.transform = val_transform\n",
        "\n",
        "# ---------- Weighted Sampler ----------\n",
        "train_labels = [full_dataset.labels_df.iloc[i]['label'] for i in train_dataset.indices]\n",
        "label_counts = Counter(train_labels)\n",
        "class_sample_counts = [label_counts[i] for i in range(len(label_counts))]\n",
        "sample_weights = [1.0 / class_sample_counts[label] for label in train_labels]\n",
        "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "# ---------- Dataloader ----------\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler, num_workers=num_workers)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "# ---------- Focal Loss ----------\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2.0):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.ce = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        logpt = -self.ce(input, target)\n",
        "        pt = torch.exp(logpt)\n",
        "        focal_loss = -((1 - pt) ** self.gamma) * logpt\n",
        "        return focal_loss.mean()\n",
        "\n",
        "criterion = FocalLoss(gamma=gamma)\n",
        "\n",
        "print(\"✅ 資料載入與 FocalLoss 建立成功！\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYC7Jleg00Ld",
        "outputId": "f10f26c9-5992-4cbd-a198-0f6bb3269443"
      },
      "id": "QYC7Jleg00Ld",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 資料載入與 FocalLoss 建立成功！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 模型 ----------\n",
        "model = models.vgg16(pretrained=True)\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "model.classifier[6] = nn.Linear(model.classifier[6].in_features, len(label_counts))\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "scaler = GradScaler()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBnkJQ7W167V",
        "outputId": "6aa4ca15-5943-4ca2-f285-b0c75a3c4761"
      },
      "id": "rBnkJQ7W167V",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-50-e2520c57adca>:10: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 訓練 ----------\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        # CutMix 機率\n",
        "        if np.random.rand() < 0.5:\n",
        "            imgs, targets1, targets2, lam = cutmix(imgs, labels)\n",
        "            outputs = model(imgs)\n",
        "            loss = lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)\n",
        "        else:\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    # ---------- 驗證 ----------\n",
        "    model.eval()\n",
        "    val_loss, correct, total = 0, 0, 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_acc = correct / total\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"[Epoch {epoch+1}] Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UPw1_Gd0HFf",
        "outputId": "e77456fb-e292-48d3-b8f0-2540ddf7ef9e"
      },
      "id": "4UPw1_Gd0HFf",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1] Train Loss: 13049.5284 | Val Loss: 7.1482 | Val Acc: 0.0117\n",
            "[Epoch 2] Train Loss: 421.9135 | Val Loss: 6.9582 | Val Acc: 0.0117\n",
            "[Epoch 3] Train Loss: 174.1341 | Val Loss: 17.0666 | Val Acc: 0.0108\n",
            "[Epoch 4] Train Loss: 90.1080 | Val Loss: 8.2442 | Val Acc: 0.0098\n",
            "[Epoch 5] Train Loss: 72.8263 | Val Loss: 5.9354 | Val Acc: 0.0108\n",
            "[Epoch 6] Train Loss: 98.2779 | Val Loss: 6.1145 | Val Acc: 0.0083\n",
            "[Epoch 7] Train Loss: 81.7987 | Val Loss: 5.2492 | Val Acc: 0.0108\n",
            "[Epoch 8] Train Loss: 44.6131 | Val Loss: 4.9535 | Val Acc: 0.0064\n",
            "[Epoch 9] Train Loss: 46.3532 | Val Loss: 4.8883 | Val Acc: 0.0147\n",
            "[Epoch 10] Train Loss: 48.6222 | Val Loss: 4.9231 | Val Acc: 0.0073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 預測 ----------\n",
        "model.eval()\n",
        "all_probs = []\n",
        "all_img_ids = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, img_ids in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)  # logits\n",
        "        probs = torch.softmax(outputs, dim=1)  # 機率分布\n",
        "\n",
        "        all_probs.extend(probs.cpu().numpy())\n",
        "        all_img_ids.extend([img_id.replace(\".jpg\", \"\") for img_id in img_ids])\n",
        "\n",
        "# ---------- 產生 submission.csv ----------\n",
        "# 取得所有類別（按排序）\n",
        "class_names = sorted(labels_df['breed'].unique())\n",
        "\n",
        "# 組成 DataFrame\n",
        "submission = pd.DataFrame(all_probs, columns=class_names)\n",
        "submission.insert(0, \"id\", all_img_ids)\n",
        "\n",
        "# 儲存成 CSV\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"✅ 已成功產生符合 Kaggle 標準的 submission.csv！\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuFazGqH504d",
        "outputId": "f8455d9c-ea6c-4057-c5f1-fb5e04502c6a"
      },
      "id": "DuFazGqH504d",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 已成功產生符合 Kaggle 標準的 submission.csv！\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c1f6b554ac6424d8233317b55897939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 1,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": "",
            "button_style": "",
            "data": [
              null
            ],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_33e27e3331b44c8abde8e85db5b7207d",
            "metadata": [
              {
                "name": "kaggle.json",
                "type": "application/json",
                "size": 64,
                "lastModified": 1745215961986
              }
            ],
            "multiple": false,
            "style": "IPY_MODEL_a2dd34b016d548eb9aee47840d68ee75"
          }
        },
        "33e27e3331b44c8abde8e85db5b7207d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2dd34b016d548eb9aee47840d68ee75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}